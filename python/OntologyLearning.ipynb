{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GATE_FOLDER = \"Path_to_gate_folder\"\n",
    "TF_IDF_FOLDER = 'Path_to_termbank_tfidf_generated_from_gate'\n",
    "FOLDER_WITH_TEXTS = 'Path_to_folder_with_texts_to_learn_ontology'\n",
    "CSV_NON_HIERARCHICAL_RELATIONS = 'Path_to_save_non_hierarchical_relations'\n",
    "HIERARCHY_IMAGE_NAME = 'Path_to_image_to_save_dendrogram'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_IDF_THRESHOLD = 0\n",
    "TOP_N_TERMS = 810\n",
    "PRE_TRAINED_BERT_MODEL = 'bert-base-uncased'\n",
    "CLUSTERING_METHOD='complete'\n",
    "CLUSTERING_METRIC ='cosine'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default\n",
    "import json\n",
    "import unicodedata\n",
    "\n",
    "# AI and Math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import glob\n",
    "\n",
    "# NLP\n",
    "from gatenlp import Document\n",
    "from gatenlp.processing.tokenizer import NLTKTokenizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from gatenlp.gateworker import GateWorker\n",
    "from gatenlp.processing.executor import SerialCorpusExecutor\n",
    "from gatenlp.gateworker import GateWorkerAnnotator\n",
    "\n",
    "import codecs\n",
    "import csv\n",
    "from functools import partial\n",
    "import gatenlp\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Versions\n",
    "print(\"NB last updated with gatenlp version\", gatenlp.__version__)\n",
    "sys.path.append(\"/home/alencga1/anaconda3/lib/python3.9/site-packages/\")\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up home variables\n",
    "import os\n",
    "os.environ[\"GATE_HOME\"] = GATE_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.ontologyextraction.schema import Term, Concept, Concept_Taxonomy\n",
    "from lib.ontologyextraction.termenrichment import termEnrichment\n",
    "from lib.ontologyextraction.helpers import find_sub_list, getTokenVecs, getWordEmbeddingFromPhrase, count_clusters, create_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TF_IDF_FOLDER, sep=',', \n",
    "            quoting=csv.QUOTE_NONE, encoding='utf8')\n",
    "# Delete duplicate rows based on specific columns \n",
    "df2 = df.drop_duplicates(subset=[\"Term\"], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = TF_IDF_THRESHOLD\n",
    "first_n = TOP_N_TERMS\n",
    "# list_terms_string = list(set(df.loc[df['tfIdf'] > threshold]['Term'].iloc[:min(first_n,df.shape[0])].values))\n",
    "list_terms_string = list(df2.loc[df2['tfIdf'] > threshold]['Term'].values)\n",
    "list_terms_string = list_terms_string[:min(first_n,len(list_terms_string))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_terms = [Term(term_string, df2.loc[df2['Term'] == term_string]['tfIdf'].iloc[0]) for term_string in list_terms_string]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_BERT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained(PRE_TRAINED_BERT_MODEL)\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_EMBEDDING_APP = partial(getWordEmbeddingFromPhrase, df, FOLDER_WITH_TEXTS, tokenizer,model, True, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in list_of_terms:\n",
    "    print(term.term_name)\n",
    "    term._Apply_Embedding(BERT_EMBEDDING_APP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find only words with actual vectors\n",
    "X = np.array(list_of_terms[0].term_embedding.tolist())\n",
    "labellist = []\n",
    "filtered_list_of_terms = []\n",
    "labellist.append(list_of_terms[0].term_name)\n",
    "filtered_list_of_terms.append(list_of_terms[0])\n",
    "for i in range(1, len(list_of_terms)):\n",
    "    term = list_of_terms[i]\n",
    "    if term.term_embedding is not None: \n",
    "        x = np.array(term.term_embedding.tolist())\n",
    "        X = np.vstack((X,x))\n",
    "        labellist.append(term.term_name)\n",
    "        filtered_list_of_terms.append(term)\n",
    "    else:\n",
    "        print(term.term_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept Hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierachical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100, 120))\n",
    "Z = sch.linkage(X, method=CLUSTERING_METHOD, metric=CLUSTERING_METRIC)\n",
    "dendrogram = sch.dendrogram(Z, labels=labellist)\n",
    "plt.savefig(HIERARCHY_IMAGE_NAME)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_clusters(dendrogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative Clustering Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = AgglomerativeClustering(n_clusters=count_clusters(dendrogram), metric=CLUSTERING_METRIC,linkage=CLUSTERING_METHOD)\n",
    "cluster.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cluster.labels_)):\n",
    "    for term in list_of_terms:\n",
    "        if term.term_name == labellist[i]:\n",
    "            term.cluster = cluster.labels_[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0,count_clusters(dendrogram)):\n",
    "    print('Cluster : ' + str(j))\n",
    "    for i in range(len(list_of_terms)):\n",
    "        if list_of_terms[i].cluster == j:\n",
    "            print('Term : ' + list_of_terms[i].term_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(labellist)):\n",
    "    if labellist[k] == 'address':\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to execute an automatic parenthood assertion, rules must be defined to organaize the process of extraction of the relation \"is_a\":\n",
    " 1. All terms are concepts\n",
    " 2. Agglomerative clustering of concepts\n",
    " 3. A cluster is a concept\n",
    " 4. A cluster concept of concepts $x$ and $y$ is going to have as term:\n",
    "    1. Either find common synonim\n",
    "    2. Either find if they are hyponyms or hypernyms of each other\n",
    "    3. Either check for similar head\n",
    "    4. Either don't give a name and group hopping that in a higher cluster a new concept will be found\n",
    " 5. As for stopping condition, either stop when the distance between clusters is past threshold or when it gets to the top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Parenthood Assertion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.ontologyextraction.schema import Term, Concept, Concept_Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in filtered_list_of_terms:\n",
    "    term = termEnrichment(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concept Creation\n",
    "list_of_concepts = []\n",
    "for term in filtered_list_of_terms:\n",
    "    concept = Concept(term.term_name,[term],descriptive_term=term)\n",
    "    list_of_concepts.append(concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conceptTaxonomy = Concept_Taxonomy(list_of_concepts)\n",
    "conceptTaxonomy.createTaxonomyFromDistanceMatrix(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_concepts = []\n",
    "for k in set(conceptTaxonomy.concept_dict.values()):\n",
    "    if(len(k.concept_name) == 0):\n",
    "        continue\n",
    "    if k not in final_concepts:\n",
    "        for x in final_concepts:\n",
    "            if x.concept_name == k.concept_name and x in k.children_concept:\n",
    "                final_concepts.remove(x)\n",
    "        final_concepts.append(k)\n",
    "print('The number of relevant deducted concepts are : ', len(final_concepts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_level = 0\n",
    "for k in final_concepts:\n",
    "    if k.level > highest_level:\n",
    "        highest_level = k.level\n",
    "print(highest_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lv in range(highest_level):\n",
    "    print('===========================================')\n",
    "    print('===========================================')\n",
    "    print('Level:' + str(lv))\n",
    "    print('-------------------------------------------')\n",
    "    for k in final_concepts:\n",
    "        if k.level == lv:\n",
    "            print(k.concept_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for concept in final_concepts:\n",
    "    print('===========================================')\n",
    "    print('===========================================')\n",
    "    print('concept name :' + concept.concept_name)\n",
    "    print('concept lv :' + str(concept.level))\n",
    "    print('concept nb children :' + str(len(concept.children_concept)))\n",
    "    print('-------------------------------------------')\n",
    "    list_of_concept_names = list(set([i.concept_name for i in concept.children_concept]))\n",
    "    for t in list_of_concept_names:\n",
    "        if(len(t) > 0):\n",
    "            print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lv3_concepts = []\n",
    "for k in final_concepts:\n",
    "    if k.level <= 3:\n",
    "        all_lv3_concepts.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for concept in all_lv3_concepts:\n",
    "    print('===========================================')\n",
    "    print('===========================================')\n",
    "    print('concept name :' + concept.concept_name)\n",
    "    print('concept lv :' + str(concept.level))\n",
    "    print('-------------------------------------------')\n",
    "    list_of_concept_names = list(set([i.concept_name for i in concept.children_concept]))\n",
    "    print(len(concept.children_concept))\n",
    "    for t in list_of_concept_names:\n",
    "        if(len(t) > 0):\n",
    "            print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkkid(concept1, concept2):\n",
    "    if concept2.children_concept is None or len(concept2.children_concept) == 0:\n",
    "        return False\n",
    "    elif concept1 in concept2.children_concept:\n",
    "        return True\n",
    "    else:\n",
    "        for concept in concept2.children_concept:\n",
    "            return checkkid(concept1, concept)\n",
    "\n",
    "def append_children(concept):\n",
    "    if concept.children_concept is None or len(concept.children_concept) == 0:\n",
    "        return [concept]\n",
    "    else:\n",
    "        list_of_concepts = []\n",
    "        for concept1 in concept.children_concept:\n",
    "            list_of_concepts += append_children(concept1)\n",
    "        list_of_concepts.append(concept)\n",
    "        return list_of_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_hierachy = []\n",
    "list_remove_later = []\n",
    "for k in set(conceptTaxonomy.deducted_concepts):\n",
    "    if(len(k.concept_name) == 0):\n",
    "        continue\n",
    "    already_in = False\n",
    "    for x in concept_hierachy:\n",
    "        if checkkid(x,k):\n",
    "            list_remove_later.append(x)\n",
    "        elif checkkid(k,x):\n",
    "            already_in=True\n",
    "    if not already_in and k not in concept_hierachy:\n",
    "        concept_hierachy.append(k)\n",
    "\n",
    "for k in list_remove_later:\n",
    "    if k in concept_hierachy:\n",
    "        concept_hierachy.remove(k)\n",
    "print('The number high level concepts are : ', len(concept_hierachy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_hierarchy(concept):\n",
    "    strf = \"\"\n",
    "    def print_sub_hierarchy(concept1, strf):\n",
    "        print('-lv: '+ str(concept1.level) + ', name : ' + concept1.concept_name)\n",
    "        for c in concept1.children_concept:\n",
    "            tmp = print_sub_hierarchy(c, strf)\n",
    "            if tmp is not None:\n",
    "                print(tmp)\n",
    "        print('------------------------------------------')\n",
    "    strf += '===========================================' + '\\n'\n",
    "    strf += '===========================================' + '\\n'\n",
    "    strf += 'concept name :' + concept.concept_name + '\\n'\n",
    "    strf += 'concept lv :' + str(concept.level) + '\\n'\n",
    "    strf += '==========================================='\n",
    "    print(strf)\n",
    "    for conceptc in concept.children_concept:\n",
    "        print_sub_hierarchy(conceptc, strf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "strf = \"\"\n",
    "for concept in concept_hierachy:\n",
    "    count += len(concept.children_concept)\n",
    "    if(len(concept.concept_name) > 0):\n",
    "        print_hierarchy(concept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-taxonomic Relation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(set(df['documentURL'].dropna().tolist()))\n",
    "X_freq = np.zeros((len(corpus), len(labellist)))\n",
    "word_list_dict = dict(zip(labellist,range(len(labellist))))\n",
    "doc_dict = dict(zip(corpus,range(len(corpus))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labellist:\n",
    "    list_of_docs = df.loc[df['Term']==label]['documentURL'].dropna().tolist()\n",
    "    for doc in list_of_docs:\n",
    "        X_freq[doc_dict[doc], word_list_dict[label]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = pd.DataFrame(np.clip(X_freq,0,1), columns=labellist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "frequent_itemsets = apriori(df_corpus, min_support = 0.5, max_len=2, use_colnames = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "relations = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.9)\n",
    "relations = relations[['antecedents','consequents']]\n",
    "display(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations.to_csv(CSV_NON_HIERARCHICAL_RELATIONS)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
